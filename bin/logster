#!/usr/bin/python -tt
# -*- coding: utf-8 -*-

###
###  logster
###
###  Tails a log and applies a log parser (that knows what to do with specific)
###  types of entries in the log, then reports metrics to Ganglia and/or Graphite.
###
###  Usage:
###
###    $ logster [options] parser logfile
###
###  Help:
###
###    $ logster -h
###
###
###  Copyright 2011, Etsy, Inc.
###
###  This file is part of Logster.
###
###  Logster is free software: you can redistribute it and/or modify
###  it under the terms of the GNU General Public License as published by
###  the Free Software Foundation, either version 3 of the License, or
###  (at your option) any later version.
###
###  Logster is distributed in the hope that it will be useful,
###  but WITHOUT ANY WARRANTY; without even the implied warranty of
###  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
###  GNU General Public License for more details.
###
###  You should have received a copy of the GNU General Public License
###  along with Logster. If not, see <http://www.gnu.org/licenses/>.
###
###  Forked from the ganglia-logtailer project
###  (http://bitbucket.org/maplebed/ganglia-logtailer):
###    Copyright Linden Research, Inc. 2008
###    Released under the GPL v2 or later.
###    For a full description of the license, please visit
###    http://www.gnu.org/licenses/gpl.txt
###

import os
import sys
import optparse
import stat
import logging.handlers
import logging.config
import traceback
import platform
import inspect

from time import time
from math import floor

# Local dependencies
from logster.logster_helper import LogsterParsingException, LockingError, LogsterOutput
from logster.tailers.logtailtailer import LogtailTailer
from logster.outputs.builtin import builtin_outputs


# Globals
log_dir = "/var/log/logster"
state_dir = "/var/run"


# optparse callback to locate output class by shortname or full path
def load_output_klass(option, opt, value, parser):
    outputs = getattr(parser.values, option.dest) if getattr(parser.values, option.dest) else []

    output_klass = builtin_outputs.get(value)
    if not output_klass:
        # Assume full path if shortname not found in builtin outputs
        try:
            module_name, output_name = value.rsplit('.', 1)
            module = __import__(module_name, globals(), locals(), [output_name])
            output_klass = getattr(module, output_name)
        except:
            parser.error("Unable to load output class %s" % value)

    # Ignore dupes
    if output_klass not in outputs:
        # Add output class-specific optparse options
        add_options = getattr(output_klass, "add_options", None)
        if callable(add_options):
            option_group = optparse.OptionGroup(parser, "%s options" % output_klass.__name__)
            add_options(option_group)
            parser.add_option_group(option_group)

        outputs.append(output_klass)

    # Append to list of outputs (option can be specified multiple times)
    setattr(parser.values, option.dest, outputs)


# As we add options during parse, their defaults don't get picked up
# (optionparser evaluates defaults once at the start of parse_args)
# This re-evaluates defaults after the parse and sets any missing
def parse_args(optionparser):
    options, arguments = optionparser.parse_args()
    post_parse_defaults = optionparser.get_default_values()
    for option in optionparser._get_all_options():
        if option.dest:
            has_default = hasattr(post_parse_defaults, option.dest)
            has_option_val = hasattr(options, option.dest)
            if has_default and not has_option_val:
                setattr(options, option.dest, getattr(post_parse_defaults, option.dest))

    return options, arguments


script_start_time = time()

# Command-line options and parsing.
cmdline = optparse.OptionParser(usage="usage: %prog [options] parser logfile",
    description="Tail a log file and filter each line to generate metrics that can be sent to common monitoring packages.")
cmdline.add_option('--tailer', '-t', action='store', default='logtail',
                    choices=('logtail', 'pygtail'), help='Specify which tailer to use. Options are logtail and pygtail. Default is \"%default\".')
cmdline.add_option('--locker', action='store', default='fcntl',
                    choices=('fcntl', 'portalocker'), help='Specify which file locker to use. Options are fcntl and portalocker. Default is \"%default\".')
cmdline.add_option('--logtail', action='store', default=LogtailTailer.default_logtail_path,
                    help='Specify location of logtail. Default \"%default\"')
cmdline.add_option('--metric-prefix', '-p', action='store',
                    help='Add prefix to all published metrics. This is for people that may multiple instances of same service on same host.',
                    default='')
cmdline.add_option('--metric-suffix', '-x', action='store',
                    help='Add suffix to all published metrics. This is for people that may add suffix at the end of their metrics.',
                    default=None)
cmdline.add_option('--parser-help', action='store_true',
                    help='Print usage and options for the selected parser')
cmdline.add_option('--parser-options', action='store',
                    help='Options to pass to the logster parser such as "-o VALUE --option2 VALUE". These are parser-specific and passed directly to the parser.')
cmdline.add_option('--state-dir', '-s', action='store', default=state_dir,
                    help='Where to store the tailer state file.  Default location %s' % state_dir)
cmdline.add_option('--log-dir', '-l', action='store', default=log_dir,
                    help='Where to store the logster logfile.  Default location %s' % log_dir)
cmdline.add_option('--log-conf', action='store', default=None,
                    help='Logging configuration file. None by default')
cmdline.add_option('--output', '-o', action='callback', callback=load_output_klass, type="string", dest="output", metavar="OUTPUT",
                   help="Where to send metrics (can specify multiple times).\
                         Choices are %s or a fully qualified Python class name" % ', '.join(builtin_outputs.keys()))
cmdline.add_option('--dry-run', '-d', action='store_true', default=False,
                    help='Parse the log file but send stats to standard output.')
cmdline.add_option('--debug', '-D', action='store_true', default=False,
                    help='Provide more verbose logging for debugging.')
cmdline.add_option('--ignore-leftover-locks', '-L', action='store_true', default=False,
                    help='Set to true if you want to recover logsters leaving the lockfile behind. Only works if your filesystem for locks have globally consistent locking (e.g. no S3FS and friends). Default is: False')
options, arguments = parse_args(cmdline)

if options.parser_help:
    options.parser_options = '-h'

if (len(arguments) != 2):
    cmdline.print_help()
    cmdline.error("Supply at least two arguments: parser and logfile.")

if options.tailer == 'pygtail':
    from logster.tailers.pygtailtailer import PygtailTailer
    tailer_klass = PygtailTailer
else:
    tailer_klass = LogtailTailer

if options.locker == 'portalocker':
    import portalocker
    lock_exception_klass = portalocker.LockException
else:
    import fcntl
    lock_exception_klass = IOError

if not (hasattr(options, 'output') and len(options.output) > 0):
    cmdline.print_help()
    cmdline.error("Supply where the data should be sent with -o (or --output).")

parser_klass_name = arguments[0]
if parser_klass_name.find('.') == -1:
    # If it's a single name, find it in the base logster package
    parser_klass_name = 'logster.parsers.%s.%s' % (parser_klass_name, parser_klass_name)
log_file   = arguments[1]
state_dir  = options.state_dir
log_dir    = options.log_dir


# Logging infrastructure for use throughout the script.
# Uses appending log file, rotated at 100 MB, keeping 5.
if (not os.path.isdir(log_dir)):
    os.mkdir(log_dir)
logger = logging.getLogger('logster')
formatter = logging.Formatter('%(asctime)s %(levelname)-8s %(message)s')
hdlr = logging.handlers.RotatingFileHandler('%s/logster.log' % log_dir, 'a', 100 * 1024 * 1024, 5)
hdlr.setFormatter(formatter)
logger.addHandler(hdlr)
logger.setLevel(logging.INFO)

if (options.log_conf):
     logging.config.fileConfig(options.log_conf)

if (options.debug):
    logger.setLevel(logging.DEBUG)

if (not os.path.isdir(state_dir)):
    os.mkdir(state_dir)


## This provides a lineno() function to make it easy to grab the line
## number that we're on (for logging)
## Danny Yoo (dyoo@hkn.eecs.berkeley.edu)
## taken from http://aspn.activestate.com/ASPN/Cookbook/Python/Recipe/145297
import inspect
def lineno():
    """Returns the current line number in our program."""
    return inspect.currentframe().f_back.f_lineno


def submit_stats(parser, duration, outputs):
    metrics = parser.get_state(duration)
    for output in outputs:
        output.submit(metrics)


def start_locking(lockfile_name):
    """ Acquire a lock via a provided lockfile filename. """
    lock_file_exists = False
    if os.path.exists(lockfile_name):
        if options.ignore_leftover_locks:
            lock_file_exists = True
        else:
            raise LockingError("Lock file (%s) already exists." % lockfile_name)

    f = open(lockfile_name, 'a')

    try:
        if options.locker == 'portalocker':
            portalocker.lock(f, portalocker.LOCK_EX | portalocker.LOCK_NB)
        else:
            fcntl.flock(f, fcntl.LOCK_EX | fcntl.LOCK_NB)

        # Let's truncate the file in case we had successfully got the lock
        f.seek(0)
        f.truncate(0)
        f.write("%s" % os.getpid())
        if lock_file_exists:
            logging.warning("Previous run of the logster might have failed, as the lockfile (%s) was found without a process holding it" % lockfile_name)

    except lock_exception_klass:
        if lock_file_exists:
            raise LockingError("Cannot acquire logster lock (%s) previous instances of the logster might be running" % lockfile_name)
        else:
            raise LockingError("Cannot acquire logster lock (%s)" % lockfile_name)

    logger.debug("Locking successful")
    return f


def end_locking(lockfile_fd, lockfile_name):
    """ Release a lock via a provided file descriptor. """
    try:
        if options.locker == 'portalocker':
            portalocker.unlock(lockfile_fd) # uses fcntl.LOCK_UN on posix (in contrast with the flock()ing below)
        else:
            if platform.system() == "SunOS": # GH issue #17
                fcntl.flock(lockfile_fd, fcntl.LOCK_UN)
            else:
                fcntl.flock(lockfile_fd, fcntl.LOCK_UN | fcntl.LOCK_NB)
    except lock_exception_klass:
        raise LockingError("Cannot release logster lock (%s)" % lockfile_name)

    try:
        lockfile_fd.close()
        os.unlink(lockfile_name)
    except OSError as e:
        raise LockingError("Cannot unlink %s" % lockfile_name)

    logger.debug("Unlocking successful")
    return


def main():
    dirsafe_logfile = log_file.replace('/','-')
    state_file = '%s/%s-%s%s.state' % (state_dir, tailer_klass.short_name, parser_klass_name, dirsafe_logfile)
    lock_file  = '%s/%s-%s%s.lock' % (state_dir, tailer_klass.short_name, parser_klass_name, dirsafe_logfile)
    tailer = tailer_klass(log_file, state_file, options, logger)

    logger.info("Executing parser %s on logfile %s" % (parser_klass_name, log_file))
    logger.debug("Using state file %s" % state_file)

    # Import and instantiate the class from the module passed in.
    module_name, parser_name = parser_klass_name.rsplit('.', 1)
    module = __import__(module_name, globals(), locals(), [parser_name])
    parser = getattr(module, parser_name)(option_string=options.parser_options)

    # Instantiate output classes
    outputs = [output_klass(cmdline, options, logger) for output_klass in options.output]

    # Check for lock file so we don't run multiple copies of the same parser
    # simultaneuosly. This will happen if the log parsing takes more time than
    # the cron period.
    try:
        lockfile = start_locking(lock_file)
    except LockingError as e:
        logger.warning(str(e))
        sys.exit(1)

    # Get input to parse.
    try:

        # Read the age of the state file to see how long it's been since we last
        # ran. Replace the state file if it has gone missing. While we are here,
        # touch the state file to reset the time in case the tailer doesn't
        # find any new lines (and thus won't update the statefile).
        try:
            state_file_age = os.stat(state_file)[stat.ST_MTIME]

            # Calculate now() - state file age to determine check duration.
            duration = floor(time()) - floor(state_file_age)
            logger.debug("Setting duration to %s seconds." % duration)

        except OSError as e:
            logger.info('Writing new state file and exiting. (Was either first run, or state file went missing.)')
            tailer.create_statefile()
            end_locking(lockfile, lock_file)
            sys.exit(0)

        # Parse each line from input, then send all stats to their collectors.
        for line in tailer.ireadlines():
            try:
                parser.parse_line(line)
            except LogsterParsingException as e:
                # This should only catch recoverable exceptions (of which there
                # aren't any at the moment).
                logger.debug("Parsing exception caught at %s: %s" % (lineno(), e))

        submit_stats(parser, duration, outputs)

    except SystemExit as e:
        raise
    except Exception as e:
        print("Exception caught at %s: %s" % (lineno(), e))
        traceback.print_exc()
        end_locking(lockfile, lock_file)
        sys.exit(1)

    # Log the execution time
    exec_time = round(time() - script_start_time, 1)
    logger.info("Total execution time: %s seconds." % exec_time)

    # Set mtime and atime for the state file to the startup time of the script
    # so that the cron interval is not thrown off by parsing a large number of
    # log entries.
    os.utime(state_file, (floor(script_start_time), floor(script_start_time)))

    end_locking(lockfile, lock_file)

    # try and remove the lockfile one last time, but it's a valid state that it's already been removed.
    try:
        end_locking(lockfile, lock_file)
    except Exception as e:
        pass

if __name__ == '__main__':
    main()

